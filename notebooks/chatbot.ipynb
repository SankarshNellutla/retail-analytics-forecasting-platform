{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot\n",
    "\n",
    "This notebook contains a minimal, chatbot that:\n",
    "- Runs a small set of safe, pre-defined SQL queries against **Postgres** database.\n",
    "- Sends the query results plus the user's question to an LLM (OpenAI) to produce a short summary + 2 suggested actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY set? -> True\n",
      "DB_URL set? -> True\n"
     ]
    }
   ],
   "source": [
    "# Imports & configuration\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from textwrap import dedent\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine, text\n",
    "from tabulate import tabulate\n",
    "import openai\n",
    "\n",
    "# Load .env\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "DB_URL = os.getenv(\"DB_URL\")\n",
    "\n",
    "print('OPENAI_API_KEY set? ->', bool(OPENAI_API_KEY))\n",
    "print('DB_URL set? ->', bool(DB_URL))\n",
    "\n",
    "if not DB_URL:\n",
    "    raise RuntimeError(\"DB_URL not found in .env. Set DB_URL=postgresql+psycopg2://user:pass@host:port/db\")\n",
    "\n",
    "if OPENAI_API_KEY:\n",
    "    openai.api_key = OPENAI_API_KEY\n",
    "else:\n",
    "    print('\\nWarning: OPENAI_API_KEY not set. LLM calls will be skipped and example placeholder text will be shown.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-defined safe SQL queries\n",
    "We keep a short list of explicit SQL templates (no user-supplied SQL) so the notebook does **not** run arbitrary SQL typed by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL_TEMPLATES = {\n",
    "    \"sales_by_region\": {\n",
    "        \"label\": \"Total sales & profit by region\",\n",
    "        \"sql\": \"\"\"\n",
    "            SELECT\n",
    "              l.region,\n",
    "              COUNT(DISTINCT o.order_id)        AS orders,\n",
    "              SUM(fs.quantity)                  AS total_qty,\n",
    "              ROUND(SUM(fs.sales)::numeric, 2)  AS total_sales,\n",
    "              ROUND(SUM(fs.profit)::numeric, 2) AS total_profit,\n",
    "              ROUND(100.0 * SUM(fs.profit) / NULLIF(SUM(fs.sales),0), 2) AS profit_margin_pct\n",
    "            FROM fact_sales fs\n",
    "            JOIN dim_location l    ON fs.location_id = l.location_id\n",
    "            JOIN dim_order o       ON fs.order_id = o.order_id\n",
    "            GROUP BY l.region\n",
    "            ORDER BY total_sales DESC\n",
    "            LIMIT 50;\n",
    "        \"\"\"\n",
    "    },\n",
    "    \"monthly_trend\": {\n",
    "        \"label\": \"Monthly sales trend (year, month)\",\n",
    "        \"sql\": \"\"\"\n",
    "            SELECT\n",
    "              o.order_year,\n",
    "              o.order_month,\n",
    "              SUM(fs.sales)::numeric(12,2)   AS month_sales,\n",
    "              SUM(fs.profit)::numeric(12,2)  AS month_profit,\n",
    "              COUNT(DISTINCT o.order_id)     AS orders_count\n",
    "            FROM fact_sales fs\n",
    "            JOIN dim_order o ON fs.order_id = o.order_id\n",
    "            GROUP BY o.order_year, o.order_month\n",
    "            ORDER BY o.order_year, o.order_month\n",
    "            LIMIT 200;\n",
    "        \"\"\"\n",
    "    },\n",
    "    \"top_customers\": {\n",
    "        \"label\": \"Top customers by lifetime sales (top 10)\",\n",
    "        \"sql\": \"\"\"\n",
    "            SELECT\n",
    "              c.customer_key,\n",
    "              c.customer_name,\n",
    "              COUNT(DISTINCT o.order_id) AS orders_count,\n",
    "              ROUND(SUM(fs.sales)::numeric,2)  AS total_sales,\n",
    "              ROUND(SUM(fs.profit)::numeric,2) AS total_profit\n",
    "            FROM fact_sales fs\n",
    "            JOIN dim_customer c ON fs.customer_id = c.customer_id\n",
    "            JOIN dim_order o     ON fs.order_id = o.order_id\n",
    "            GROUP BY c.customer_key, c.customer_name\n",
    "            ORDER BY total_sales DESC\n",
    "            LIMIT 10;\n",
    "        \"\"\"\n",
    "    },\n",
    "    \"top_products\": {\n",
    "        \"label\": \"Top products by profit (top 10)\",\n",
    "        \"sql\": \"\"\"\n",
    "            SELECT\n",
    "              p.product_key,\n",
    "              p.product_name,\n",
    "              p.category,\n",
    "              p.sub_category,\n",
    "              SUM(fs.sales)::numeric(12,2)   AS total_sales,\n",
    "              SUM(fs.profit)::numeric(12,2)  AS total_profit,\n",
    "              SUM(fs.quantity)               AS total_qty\n",
    "            FROM fact_sales fs\n",
    "            JOIN dim_product p ON fs.product_id = p.product_id\n",
    "            GROUP BY p.product_key, p.product_name, p.category, p.sub_category\n",
    "            ORDER BY total_profit DESC\n",
    "            LIMIT 10;\n",
    "        \"\"\"\n",
    "    }\n",
    "}\n",
    "\n",
    "def detect_intent(user_text: str):\n",
    "    t = user_text.lower()\n",
    "    if re.search(r\"\\b(region|by region|regions)\\b\", t) and re.search(r\"\\b(sales|profit|revenue)\\b\", t):\n",
    "        return \"sales_by_region\"\n",
    "    if re.search(r\"\\b(month|monthly|trend|history)\\b\", t) and re.search(r\"\\b(sales|profit)\\b\", t):\n",
    "        return \"monthly_trend\"\n",
    "    if re.search(r\"\\b(top|best|highest)\\b\", t) and re.search(r\"\\b(customers|clients)\\b\", t):\n",
    "        return \"top_customers\"\n",
    "    if re.search(r\"\\b(top|best|highest)\\b\", t) and re.search(r\"\\b(product|products)\\b\", t):\n",
    "        return \"top_products\"\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions: run SQL and ask the LLM\n",
    "The code uses `openai.ChatCompletion.create` to ask the model for a short summary. If `OPENAI_API_KEY` is not set,\n",
    "the notebook will print placeholder text instead of making the API call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sql_return_table(db_engine, sql_text):\n",
    "    with db_engine.connect() as conn:\n",
    "        result = conn.execute(text(sql_text))\n",
    "        cols = result.keys()\n",
    "        rows = result.fetchall()\n",
    "    return cols, rows\n",
    "\n",
    "def ask_llm_system_and_user(system_prompt: str, user_prompt: str, model: str = \"gpt-4o-mini\", max_tokens: int = 300):\n",
    "    \"\"\"\n",
    "    Minimal, robust helper that:\n",
    "    - Prefers the new OpenAI client (openai>=1.0.0)\n",
    "    - Falls back to the legacy openai.ChatCompletion.create if needed\n",
    "    - Safely extracts assistant text from a few possible response shapes\n",
    "    \"\"\"\n",
    "    if not OPENAI_API_KEY:\n",
    "        return \"(OPENAI_API_KEY not set — LLM call skipped; set OPENAI_API_KEY in .env to enable.)\"\n",
    "\n",
    "    def _extract_text_from_choice(choice):\n",
    "        # Try several common shapes (attribute-style and dict-style)\n",
    "        try:\n",
    "            # new client: choice.message.content (attribute)\n",
    "            if hasattr(choice, \"message\"):\n",
    "                msg = choice.message\n",
    "                if hasattr(msg, \"content\"):\n",
    "                    return msg.content\n",
    "                if isinstance(msg, dict):\n",
    "                    return msg.get(\"content\")\n",
    "            # dict-like shape\n",
    "            if isinstance(choice, dict):\n",
    "                m = choice.get(\"message\") or {}\n",
    "                if isinstance(m, dict):\n",
    "                    return m.get(\"content\") or m.get(\"text\")\n",
    "                return choice.get(\"text\")\n",
    "            # fallback: maybe attribute 'text'\n",
    "            if hasattr(choice, \"text\"):\n",
    "                return choice.text\n",
    "        except Exception:\n",
    "            pass\n",
    "        return None\n",
    "\n",
    "    # Try new SDK first\n",
    "    try:\n",
    "        from openai import OpenAI\n",
    "        client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "        resp = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt},\n",
    "            ],\n",
    "            max_tokens=max_tokens,\n",
    "            temperature=0.0,\n",
    "        )\n",
    "        if getattr(resp, \"choices\", None):\n",
    "            content = _extract_text_from_choice(resp.choices[0])\n",
    "            if content:\n",
    "                return content.strip()\n",
    "        # If we didn't find the text, raise to trigger fallback or show an informative error\n",
    "        raise RuntimeError(f\"Could not extract assistant text from new-client response: {resp}\")\n",
    "    except Exception as new_err:\n",
    "        # Try legacy ChatCompletion (older openai versions)\n",
    "        try:\n",
    "            resp = openai.ChatCompletion.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt},\n",
    "                ],\n",
    "                max_tokens=max_tokens,\n",
    "                temperature=0.0,\n",
    "            )\n",
    "            # legacy shape usually: resp.choices[0].message.content\n",
    "            try:\n",
    "                return resp.choices[0].message.content.strip()\n",
    "            except Exception:\n",
    "                # fallback for dict-like\n",
    "                content = _extract_text_from_choice(resp.choices[0])\n",
    "                if content:\n",
    "                    return content.strip()\n",
    "                raise\n",
    "        except Exception as old_err:\n",
    "            return f\"(LLM call failed — new_client_error={new_err}; legacy_error={old_err})\"\n",
    "\n",
    "def format_table_for_user(cols, rows, max_rows=20):\n",
    "    rows_to_show = rows[:max_rows]\n",
    "    return tabulate(rows_to_show, headers=cols, tablefmt=\"psql\", showindex=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `run_chat_query` - single entry point\n",
    "Call this function with a short natural-language question. It will:\n",
    "1. Detect intent (map to one of the safe SQL templates)\n",
    "2. Execute the SQL against your DB\n",
    "3. Show raw top rows\n",
    "4. Ask the LLM to summarize and suggest two actions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_chat_query(user_text: str, db_url: str = DB_URL):\n",
    "    intent = detect_intent(user_text)\n",
    "    if intent is None:\n",
    "        print(\"Sorry — only a few direct queries are supported. Try: 'Show sales by region', 'monthly sales trend', 'top customers', 'top products'.\")\n",
    "        return\n",
    "    template = SQL_TEMPLATES[intent]\n",
    "    print(f\"[RUN] Executing: {template['label']}\")\n",
    "    engine = create_engine(db_url, pool_pre_ping=True)\n",
    "    cols, rows = run_sql_return_table(engine, template['sql'])\n",
    "    print('\\n=== Raw results (top rows) ===')\n",
    "    print(format_table_for_user(cols, rows, max_rows=12))\n",
    "\n",
    "    sample_rows_json = json.dumps([dict(zip(cols, r)) for r in rows[:8]], default=str)\n",
    "    system_prompt = \"You are a concise business analyst. Produce a short (2-4 sentences) insight and 2 suggested next actions.\"\n",
    "    user_prompt = dedent(f\"\"\"\n",
    "        User question: \"{user_text}\"\n",
    "        SQL label: \"{template['label']}\"\n",
    "        Top rows (as JSON): {sample_rows_json}\n",
    "        Provide:\\n 1) A short (2-4 sentence) plain-English summary of what the numbers show.\\n 2) Two actionable suggestions (one analysis step, one business action).\\n\n",
    "    \"\"\")\n",
    "    llm_reply = ask_llm_system_and_user(system_prompt, user_prompt)\n",
    "    print('\\n--- LLM Summary & Actions ---')\n",
    "    print(llm_reply)\n",
    "    engine.dispose()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: run a query\n",
    "Uncomment and run the line below. If you don't have `OPENAI_API_KEY` set, the notebook will still run the SQL and show raw results but won't call the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook ready. Call run_chat_query(...) with one of the supported questions.\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "# run_chat_query('Show sales by region')\n",
    "# run_chat_query('Give me monthly sales trend')\n",
    "# run_chat_query('Who are the top customers?')\n",
    "\n",
    "print('Notebook ready. Call run_chat_query(...) with one of the supported questions.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes & next steps\n",
    "- This notebook is intentionally minimal. If you want interactive chat (text input boxes), we can add an `ipywidgets` cell.\n",
    "- If you want the LLM to accept more free-form questions, we can implement a small NLP intent classifier — but that is optional.\n",
    "\n",
    "You're good to go: place this notebook in your repo, set your `.env`, and run the example queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30cff352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RUN] Executing: Top customers by lifetime sales (top 10)\n",
      "\n",
      "=== Raw results (top rows) ===\n",
      "+----------------+--------------------+----------------+---------------+----------------+\n",
      "| customer_key   | customer_name      |   orders_count |   total_sales |   total_profit |\n",
      "|----------------+--------------------+----------------+---------------+----------------|\n",
      "| SM-20320       | Sean Miller        |              5 |       25043   |       -1980.74 |\n",
      "| TC-20980       | Tamara Chand       |              5 |       19052.2 |        8981.32 |\n",
      "| RB-19360       | Raymond Buch       |              6 |       15117.3 |        6976.1  |\n",
      "| TA-21385       | Tom Ashbrook       |              4 |       14595.6 |        4703.79 |\n",
      "| AB-10105       | Adrian Barton      |             10 |       14473.6 |        5444.81 |\n",
      "| KL-16645       | Ken Lonsdale       |             12 |       14175.2 |         806.86 |\n",
      "| SC-20095       | Sanjit Chand       |              9 |       14142.3 |        5757.41 |\n",
      "| HL-15040       | Hunter Lopez       |              6 |       12873.3 |        5622.43 |\n",
      "| SE-20110       | Sanjit Engle       |             11 |       12209.4 |        2650.68 |\n",
      "| CC-12370       | Christopher Conant |              5 |       12129.1 |        2177.05 |\n",
      "+----------------+--------------------+----------------+---------------+----------------+\n",
      "\n",
      "--- LLM Summary & Actions ---\n",
      "The data reveals the top customers by lifetime sales, highlighting that Sean Miller, despite having the highest sales, has a negative profit, indicating potential issues with pricing or cost management. In contrast, Tamara Chand shows strong sales and profit, suggesting a more sustainable customer relationship. \n",
      "\n",
      "**Actionable Suggestions:**\n",
      "1. Conduct a detailed analysis of Sean Miller's orders to identify the reasons for the negative profit, focusing on pricing strategies and cost structures.\n",
      "2. Develop targeted marketing strategies to enhance customer loyalty and increase sales from profitable customers like Tamara Chand and others in the top tier.\n"
     ]
    }
   ],
   "source": [
    "run_chat_query('top customers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "586aaacf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorry — only a few direct queries are supported. Try: 'Show sales by region', 'monthly sales trend', 'top customers', 'top products'.\n"
     ]
    }
   ],
   "source": [
    "run_chat_query('Hiii')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
